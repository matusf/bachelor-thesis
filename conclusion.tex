\chapter{Conclusion}
In this chapter, we will present the possible enhancements that can be done to improve our fuzzer. Additionally, we will conclude our findings and summarize our work.

\section{Future work}
We explored the possibility of fuzzing an API with help of OpenAPI specification and created a fuzzer that uses the specification uniquely. However, the potential of utilizing OpenAPI specification in API fuzzing is not used up at all. In the following paragraphs, we will discuss some additional work that could be done to improve the fuzzer.

\subsection{Checking authorization}
As discussed in a chapter regarding the OpenAPI specification (section \ref{sec:openapi}), we stated that OpenAPI specification allows the APIs to mark which endpoints are authorized. We could use this knowledge in a fuzzing. The fuzzer running an unauthorized session could be sending requests to those endpoints, and when it would receive any other response than \texttt{401 - Unauthorized} the fuzzer would mark it as a finding. Thanks to this technique, we would be able to find those bugs and to strengthen the security of APIs even more by not letting unauthorized users retrieve any information.

\subsection{Expanding randomization}
There are lots of things we can further randomize. As for now, we always send all possible parameters, headers, cookies, and other types of inputs. We deem that by sending every possible form of input, the fuzzer will achieve higher code coverage. Nonetheless, it would be interesting not to send all possible inputs and examine how would the APIs handle these types of situations. Moreover, some parts of the requests are marked in the specification as required. We could try not sending them as well as inspect the behavior of the API.

\subsubsection{Randomizing HTTP methods}
When we were talking about randomizing input, we wanted only to augment it. Mostly, by breaking the specification and not sending some parts. Nevertheless, we can try to send something that the APIs do not expect, too. While sending the random data to the API would be ineffective since it would not test the underlying logic but rather the input parser, sending requests with different HTTP methods might be worthwhile. We may ask ourselves, why is it the case? There is only a handful of HTTP methods, so trying all of them will not take a long time. Furthermore, when API responds with anything other than HTTP status code \texttt{405 - Method Not Allowed} it is an indication that the API is listening on that endpoint (with a specified method). This knowledge can be subsequently used to examine the endpoint and potentially exploit it. Teddy Katz was able to bypass GitHub's OAuth flow by sending a request to an endpoint with an undocumented HTTP method \cite{kartz2019bypass}. This functionality would make it possible to locate the vulnerability automatically without time-demanding decompilation of source code.


\section{Closing thoughts}
% use as spec verification
The need for providing production-grade quality software was there from the inception of software engineering. The most effective way to ensure the quality of software proved to be testing. Throughout the history of computer science, software engineers and architects came up with different testing methods and techniques. Nonetheless, the manual way of writing tests proved insufficient, and therefore random walk testing - fuzzing was invented \cite{miller1990empirical}.

However, as more and more applications moved from PCs to the web, a new challenge arose. Engineers needed to find a way to effectively fuzz the web applications. Our focus was primarily on this aspect of the fuzzing. We researched different existing implementations of web fuzzers. We found a way to get the description of the web services and subsequently create a fuzzer that utilizes it to fuzz APIs automatically. With our unique generation-based \textit{smart} black-box fuzzer, we were able to find bugs in such battle-tested web services as Kubernetes, Gitea, and Vault.
