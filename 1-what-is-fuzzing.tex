\chapter{Introduction to fuzzing}
\label{cha:Introduction to fuzzing}
The issue of providing production grade software was there from the inception of a software engineering. Engineers used numerous testing methods to achieve assure the quality. Most widely used testing methods were unit testing and integration testing.

Unit testing consists of running automated test units where each unit tests a specific part of the application, like a couple of function or whole interface. Unit testing therefore enforces the correctness of individual parts of the application and thus it enables faster recfactorization. Nonetheless, to create selfcontained testable units, we often need to mock some parts of it, which may result in some parts being untested.

Integration testing on the other hand does not run small units. It combines all units of the application and test their integration together. One possible disadvantage of integration testing is that mainly the expected path is tested. Moreover, random inputs are provided rather seldomly.

One of most frequent bugs caught by fuzzers are buffer overflows, memory leaks and formatting errors. This sort of bugs may seem inocent and one might think that they will only crash the application. On the contrary, this bugs may leed to serious vulnerabilities such as heartbleed bug \cite{heartbleed2020bug} in widely used TLS implementation, which caused primary keys to leak and thus exposed the entire communication unencrypted. Additionally, there is an example implementation of how to find the heartbleed vulnerability right in the ClusterFuzz documentation \cite{clusterfuzz2020heartbleed}.

\section{Why is fuzzing?}
The above mentioned testing methods, however, proved insufficient when Miller with his team were able to crash from 24 to 33 percent of nearly 90 unix battle tested utilities. They were generating random inputs and reporting the error if program crashed or hanged. Miller described the fuzz testing strategy as a random walk through state space of a program, represented by a state machine, searching for undefined states \cite{miller1990empirical}.

The success of random walk testing - fuzzing, did not ended there. Nevertheless, before we look into differrent successful fuzzers, let's categorize them. Categorization will allow us to describe them more precisely.


\section{Types of fuzzers}
\label{sub:Types of fuzzers}
We can differentiate fuzzers according to the three categories.
\begin{enumerate}
    \item White-box, gray-box or black-box fuzzers
    \item \emph{Dumb} or \emph{smart} fuzzers
    \item Generation-based or mutation-based fuzzers
\end{enumerate}

\subsection{White-box gray-box and black-box fuzzers}
\label{ssub:White-box gray-box and black-box fuzzers}
\textbf{White-box fuzzers} are aware of the internal structure of the program. Thus, they need to have access to the source code of the program. They use a program analysis to increase a code coverage \cite{neystadt2008automated}. We may define code coverage as a measurement of how much of the state space is reached during the random walk. In case of available program specification, the fuzzer may leverage techniques from model-based testing to generate testing  inputs and subsequently verify it with the specification. White-box fuzzers, however, may need a substantial time to be integrated with the fuzzed target.

\textbf{Black-box fuzzers} on the other hand are not aware of the program structure. They treat the program as a black-box. They test the compiled version of the program \cite{takanen2018fuzzing}. Since the black-box fuzzers do not need to know anything about the program structure, they tend to be more performant and reusable. Hight level of paralelization can be usually applied as well. Additionally, black-fuzzing is often combined with \emph{smart} fuzzing technique \cite{neystadt2008automated}, about which we will talk in a while. The disadvantage of the black-box fuzzing technique is that it may not achieve as high code coverage as white-box fuzzer due to not having any knowledge about the program structure.

\textbf{Gray-box fuzzing} can be described as a combination of black-box and white-box fuzzing techniques. Gray-box testing uses for leverages intrumentation technique like profiling to analyze the program while not having the access to its source code. The gray-box fuzzing has the advantage of being more thorough than black-box fuzzing and being faster than white-box fuzzing.


\subsection{\emph{Dumb} and \emph{smart} fuzzers}
\label{ssub:Dumb and smart fuzzers}
The primary job of a fuzzer is to generate some input. The input should be \emph{valid enough} that it will not be rejected directly by a parser. But it should be \emph{invalid enough} that it will test the program thoroughly as well.

\textbf{\emph{Smart} fuzzer} knows the structure of the input data. For instance, it knows that it will be fuzzing application that uses specific protocol. Thus, it will comply with the protocol by sending data in appropriate format, computing the correct check sums, etc. Then it will send the fuzzed input via this protocol in correct a format.

On the other hand, \textbf{\emph{Dumb} fuzzer} does not know anything about the input structure. It may take the input that is accepted by the program and start fliping some bits in it or insertind some random sequences of bits. This approach has the obvoius disadvantage when compared to the \emph{smart} fuzzer. It will generate a lot of input that will be rejected right away by the input parser of the program. Advantage of \emph{dumb} fuzzer is its reusability and easier implementation.

\subsection{Generation-based and mutation-based fuzzers}
\label{ssub:Generation-based and mutation-based fuzzers}
Whether the fuzzer is generation-based and mutation-based depends on how the input data is created.

\textbf{Mutation-based} fuzzer creates new input from valid input \cite{miller2007analysis}. It may for instance collect some files or network traffic, modify it by applying heuristics or randomness and subsequently use it as a new input. A such modification might include changing the length of some parameters or changing the signess of some integer parameters.

\textbf{Generation-based} fuzzer generates the input data is created from scratch based on a RFC or other specification \cite{miller2007analysis}. This approach may sometimes generate an input that is valid an have too little randomness. Moreover,the need for specification makes the implementation of the fuzzer more difficult. On the other side, Muller showed that generation-based fuzzing possesses benefits and performs up to 76\% better when compared to mutation-based fuzzing techniques \cite{miller2007analysis}.


\section{Significant fuzzers}
\label{ssub:Significant fuzzers}
To understand the importance of fuzzing more, let's list some successful fuzzers along with their successful bug and vulnerability doscoveries. We will explore the architectures and interesting properties as well.

\subsection{american fuzzy lop}
American fuzzy lop is a security-oriented fuzzer that employs a novel type of compile-time instrumentation and genetic algorithms to automatically discover clean, interesting test cases that trigger new internal states in the targeted binary \cite{zalewski2018american}. The american fuzzy lop discovered many bugs in battle-tested software. Some of the highlights are bugs discovered in Mozzilla \cite{zalewski2014uninitialized, zalewski2014two, zalewski2015uninitialized, mozzilla2015update} differrent SSL/TLS implementations \cite{bock2015out, sharma2014gnutls}, image file formats \cite{zalewski2013ijg, cunningham2014segv} and many others.


Following features make american fuzzy lop successful:
\begin{itemize}
    \item it is fast due to low-level compile-time or binary only instrumentation
    \item it uses high-gain test case preprocessing and fuzzing strategies that hepls it discover even subtle and other hard-to-catch bugs
    \item it is battery included and comes with various tools like crash explorer, a test case minimizer, a fault-triggering allocator and a syntax analyzer
\end{itemize}

\subsection{syzkaller}
Another fuzzer than is worth to mention syzkaller. Syzkaller is an unsupervised coverage-guided fuzzer that focusses on kernel fuzzing. It generates syscalls based on syscall description, eximines the coverage produced by executed syscall and mutates the ones that were able to increate the coverage. The number of found bugs in Linux kernel speaks for itself. Syzkaller found hundreds of them \cite{syzkaller2020bugs}. Another interesting thing about syzkaller is that it can be fully automated to fuzz and subsequently report found bugs.


\subsection{ClusterFuzz}


\section{From OS to API}
Nowadays, more and more applications are offered as online services.

\subsection{What are microservices?}

\subsection{What is OpenAPI?}
OpenAPI specification, previously known as swagger, was standardized in () and adopted by the Linux Foundation. The specification describes an API. This gives us advantage of knowing the input structure, thus making it easier to make \emph{smart} fuzzer.

\section{Why black-box instead of white-box testing?}
In case of performing offensive security we might not have access to the source code of the target to perform some analysis. We will only be able to access some interface ot the target. This is even more true when it comes to web services.
