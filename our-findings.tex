\chapter{Our findings}
In this chapter we will focus on the act of fuzzing. We will describe against which software we run our fuzzer, what types and how many bugs we have found. We will also make a comparison between an authorized session and unauthorized one. Additionaly, we will talk about the time it takes to find the first bug and how the number of found bugs increases it time.

\section{Testing setup}
We strived for our fuzzer to be simple and easy to use. Moreover, we did not want out fuzzer to require any special or over-powered hardware. To prove our point and also out of necessity, we have not used any advanced architecture for the fuzzing. All fuzzed software is open-source and we ran it locally along with the fuzzer. To be more concrete, all software was running on our personal notebook. Other properties, like running time differed amongst the sowtware and we will detail it in following paragraphs.

\section{How we count bugs}
When we were fuzzing a sowtware for the first time it unsually produced a lot of false posivive result. This happens because APIs tend not to include all possible status codes in the OpenAPI specification. However, we were always able to promptly ignore HTTP status codes that we were not interested in by a CLI flag. Those status codes were mainly from the client errors range (among most common were \texttt{404} or \texttt{401}).

After the fuzzing finished, we found out that the fuzzer produced multiple results. We decided to focus mainly on the requests that caused internal server error since we consider them more severe. We also reported only the internal server errors to the maintainers yet to keep the spam to minimum. Although, the other results are to be considered at least as a documentation bug and are worth further investigation.

To conclude it, we count a request on specific endpoint using specific method as a single bug. Eventhough the fuzzer was able to create multiple such requests. To put it into perspective, the number of bugs is equal to the number of subdirectories of results directory tree that with name \texttt{500} which can be seen in figure \ref{fig:openapi-fuzzer-results}. It the case described in figure \ref{fig:openapi-fuzzer-results} the number of bugs would be 2.

\section{Let us fuzz}
We started out fuzzing journey with software, we deemed was the easiet to crash due to its language of implementation. The first software we fuzzed is \textbf{RESTful-DOOM} which an implementation of well-known game with REST API on top of it \cite{doom2020github}. It does not provide an OpenAPI specification, however, its API is described by RAML specification - a competing specification \cite{raml2020web}. Nevertheless, it was not an issue since there are different convertors between the specification. This game is programed in C language and indeed we expoited one of inherent weaknesses of the C - the memory safaty management. The OpenAPI Fuzzer was able to crash it matter of seconds by causing a segmentation violation error. This quick success encouraged us to proceed with fuzzing more and more advanced sowtware.

\paragraph{}
The first one among the well-known battle-tested software we fuzzed is \textbf{HashiCorp Vault}. HashiCorp Vault is a tool for secrets management, encryption as a service, and privileged access management \cite{vault2020github}. Vault is used by companies including Adobe, Shopify, Barclays, AstraZeneca and others \cite{vault2021web}. Vault is implemented in a memory safe language called Go devepoled by a team focused on security so we knew it would not be an easy target. Our first run was an unauthorized one and produced 3 different bugs in 2 hours and 3 others in next 3 hours. Then we went ahead and ran an authorized session which yielded 8 bugs after 2 hours and additional one after 24 hours. At first we were not able to gain much information about the types of the bugs since Vault does not produce many log messages. However, after we dug deeper, we were able to minimize the bugs and report them. One of causes of the bugs was number parsing where the Vault expected to receive only non-negative number, but a negative one caused an internal server error. Another one was caused by quering non-existent entity. We submitted issues to all the bugs and received an acknowledgment response to the minimized ones (\cite{vaultissue11304github}, \cite{vaultissue11306github}, \cite{vaultissue11308github}, \cite{vaultissue11310github}, \cite{vaultissue11311github}, \cite{vaultissue11313github}, \cite{vaultissue11314github}, \cite{vaultissue11315github}).

\paragraph{}
The next software we fuzzed is \textbf{Gitea}. Gitea is a self-hoted Git service that describes itself as a community managed lightweight code hosting solution written in Go \cite{gitea2020web}. We ran a quick unauthorized session, however, after a while of not getting any relevant results we decided to run an authorized one. During the authorized run we have found 4 bugs out of which we were able to reproduce and report 3 of them (\cite{giteaissue15346github}, \cite{giteaissue15357github}, \cite{giteaissue15356github}). All 3 of them were acknowledged by the maintainers and further discussed. Moreover, 2 of them are already fixed and will be included in next release. Since Gitea provides detailed logs we were able to quickly find the cause of the issues. Two of the bugs were caused by quering non-existent entity and the other one was caused by unhandled date parsing failure.

\paragraph{}
The last software we took a look at is \textbf{Kubernetes} or simply \textbf{k8s}. Kubernetes is an open-source container-orchestration system for automating computer application deployment, scaling, and management which was created by Google and now it is maintained by the Cloud Native Computing Foundation \cite{k8s2021web}. It is consider to be de-facto standard in cloud computing. As before we ran kubernetes in two times. The first time we ran an unauthorized session for 10 hours during which we were not able to find any bugs. During the authorized session we were able to trigger 14 bugs in 65 hours. Nonetheless, after further inspection we came to conclusion that 12 of them were caused by the same underlining bug. All 12 endpoints were taking the same query parameter which if was supplied in an incorrect format failed the operation and resulted in an internal server error. Therefore, when filing issues for the bugs we decided to mark it as a one bug. All 3 issues received acknowledgment and there are already two pull requests for fixing the bugs (\cite{k8sissue101355github}, \cite{k8sissue101350github}, \cite{k8sissue101348github}). As for the types of bugs, one was caused by unhandled version parsing failure, anotherone was caused by quering file with too long name and the last one was caused by quering non-existent entity.

\paragraph{}
\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c c c c|}
\hline
Fuzzed software & Vault & Vault\textsuperscript{A} & Gitea\textsuperscript{A} & kubernetes\textsuperscript{A} \\
\hline
time to majority bugs & 20' & 2h  & -  & 15h \\
number of bugs        & 3   & 8   & -  & 13  \\
\hline
total time            & 24h & 24h & 6h & 65h \\
total number of bugs  & 6   & 9   & 4  & 14  \\
\hline
\end{tabular}
\caption[Comparison of result between fuzzed services]{Comparison of result between fuzzed services\\(service with \textsuperscript{A} were running an authorized session)}
\label{table:fuzzed-software}
\end{center}
\end{table}

As we are able to see the OpenAPI Fuzzer was largely successful when fuzzing the APIs. It found bugs in battle-tested production grade software and was able to report them in a form, that we could easily file all bug reports. Moreover, we see from the table \ref{table:fuzzed-software} that authorization is rather useful when we want to increase the code coverage. All authorized runs produced more results than the unauthorized ones. The poor results from unauthorized runs were caused by the APIs shor-circuiting the flow - when the authorization is not provided the APIs will usually not even try to parse the payload and return a HTTP status code signalling that authorization is needed. Additionaly, we can also see that the majority of the bugs are found quite quickly. On the other side, it takes noticably more time to find the remaining bugs.
